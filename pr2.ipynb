{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train_Lines', 800)\n"
     ]
    }
   ],
   "source": [
    "#read train file\n",
    "train_data = open('C:/Users/saish/Desktop/A_PR2/train.dat','r')\n",
    "tr_lines = train_data.readlines()\n",
    "\n",
    "tr_len = len(tr_lines)\n",
    "print ('Train_Lines', tr_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predict = []\n",
    "tr_set = []\n",
    "\n",
    "\n",
    "for i in range(tr_len):\n",
    "    line = tr_lines[i]\n",
    "    tr_line_len = len(line)\n",
    "    for l in range(tr_line_len):\n",
    "        if l == 1:\n",
    "            predict.append(line[0:1])\n",
    "\n",
    "for tr_l in tr_lines:       \n",
    "    tr_l = tr_l.replace(\"0\\t\", \"\")\n",
    "    tr_l = tr_l.replace(\"1\\t\", \"\")\n",
    "    tr_l = tr_l.replace(\"\\n\", \"\")\n",
    "    tr_l = tr_l.split()       \n",
    "    tr_set.append(tr_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tr_feature = []\n",
    "fr_cnt = 100001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for tr in tr_set:\n",
    "    tr_feature_set = [0]*fr_cnt\n",
    "    for v in tr:\n",
    "        tr_feature_set[int(v)] = 1\n",
    "    tr_feature.append(tr_feature_set)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test_Lines', 350)\n"
     ]
    }
   ],
   "source": [
    "#read test file\n",
    "test_data = open('C:/Users/saish/Desktop/A_PR2/test.dat','r')\n",
    "ts_lines = test_data.readlines()\n",
    "\n",
    "#Get number of records\n",
    "ts_len = len(ts_lines)\n",
    "print ('Test_Lines', ts_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ts_set = []\n",
    "for ts_l in ts_lines:       \n",
    "    ts_l = ts_l.replace(\"0\\t\", \"\")\n",
    "    ts_l = ts_l.replace(\"1\\t\", \"\")\n",
    "    ts_l = ts_l.replace(\"\\n\", \"\")\n",
    "    ts_l = ts_l.split()   \n",
    "    ts_set.append(ts_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ts_feature = []\n",
    "fs_cnt = 100001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for ts in ts_set:\n",
    "    ts_feature_set = [0]*fs_cnt\n",
    "    for v in ts:\n",
    "        ts_feature_set[int(v)] = 1\n",
    "    ts_feature.append(ts_feature_set)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SAMPLING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "maj_c = []\n",
    "min_c = []\n",
    "\n",
    "for cnt, val in enumerate(predict):\n",
    "         if  val == '1':\n",
    "             min_c.append(cnt)\n",
    "         else:\n",
    "             maj_c.append(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Majority class split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#majority class split\n",
    "maj_len = len(maj_c)\n",
    "maj_70 = int((maj_len)*0.70)\n",
    "maj_70_ind = []\n",
    "maj_30_ind = []\n",
    "\n",
    "\n",
    "#get feature set index\n",
    "for i in range(maj_len):\n",
    "    if (i<= maj_70):\n",
    "        maj_70_ind.append(maj_c[i])\n",
    "    else:\n",
    "        maj_30_ind.append(maj_c[i])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#get feature set\n",
    "new_tr_ft_mj = []\n",
    "new_tr_pd_mj = []\n",
    "for i in maj_70_ind:\n",
    "    new_tr_ft_mj.append(tr_feature[i])\n",
    "    new_tr_pd_mj.append(predict[i])\n",
    "    \n",
    "\n",
    "new_vl_ft_mj = []\n",
    "new_vl_pd_mj = []\n",
    "for i in maj_30_ind:\n",
    "    new_vl_ft_mj.append(tr_feature[i])\n",
    "    new_vl_pd_mj.append(predict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('length of train', 506)\n",
      "('length of test', 216)\n"
     ]
    }
   ],
   "source": [
    "print ('length of train', len(new_tr_ft_mj))\n",
    "print ('length of test', len(new_vl_ft_mj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Minority class split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#majority class split\n",
    "min_len = len(min_c)\n",
    "min_70 = int((min_len)*0.70)\n",
    "min_70_ind = []\n",
    "min_30_ind = []\n",
    "\n",
    "\n",
    "#get feature set index\n",
    "for i in range(min_len):\n",
    "    if (i<= min_70):\n",
    "        min_70_ind.append(min_c[i])\n",
    "    else:\n",
    "        min_30_ind.append(min_c[i])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('length of train', 55)\n",
      "('length of test', 23)\n"
     ]
    }
   ],
   "source": [
    "#get feature set\n",
    "new_tr_ft_mi = []\n",
    "new_tr_pd_mi = []\n",
    "for i in min_70_ind:\n",
    "    new_tr_ft_mi.append(tr_feature[i])\n",
    "    new_tr_pd_mi.append(predict[i])\n",
    "    \n",
    "\n",
    "new_vl_ft_mi = []\n",
    "new_vl_pd_mi = []\n",
    "for i in min_30_ind:\n",
    "    new_vl_ft_mi.append(tr_feature[i])\n",
    "    new_vl_pd_mi.append(predict[i])\n",
    "\n",
    "print ('length of train', len(new_tr_ft_mi))\n",
    "print ('length of test', len(new_vl_ft_mi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('length of final train', 561)\n",
      "('length of final train pred', 561)\n",
      "('length of final test', 239)\n",
      "('length of final test pred', 239)\n"
     ]
    }
   ],
   "source": [
    "final_tr_set = new_tr_ft_mj + new_tr_ft_mi\n",
    "print ('length of final train', len(final_tr_set))\n",
    "\n",
    "final_tr_pred = new_tr_pd_mj + new_tr_pd_mi\n",
    "print ('length of final train pred', len(final_tr_pred))\n",
    "\n",
    "final_vl_set = new_vl_ft_mj + new_vl_ft_mi\n",
    "print ('length of final test', len(final_vl_set))\n",
    "\n",
    "final_vl_pred = new_vl_pd_mj + new_vl_pd_mi\n",
    "print ('length of final test pred', len(final_vl_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "tr_feature_sm, predict_sm = SMOTE().fit_sample(tr_feature, predict)\n",
    "from collections import Counter print(sorted(Counter(predict_sm).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(algorithm='randomized', n_components=800, n_iter=10, random_state=42)\n",
    "tr_svd = svd.fit_transform(tr_feature, predict)\n",
    "final_tr_set_svd = svd.transform(final_tr_set)\n",
    "final_vl_set_svd = svd.transform(final_vl_set)\n",
    "ts_svd = svd.transform(ts_feature)\n",
    "print(svd.explained_variance_ratio_.sum())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800L, 800L)\n",
      "(561L, 800L)\n",
      "(239L, 800L)\n"
     ]
    }
   ],
   "source": [
    "print(tr_svd.shape)\n",
    "print(final_tr_set_svd.shape)\n",
    "print(final_vl_set_svd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classifiers_list = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(n_neighbors=9),\n",
    "    \"Linear SVM\": SVC(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier( ),\n",
    "    \"Neural Net1\": MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(19, 5), random_state=1),\n",
    "    #\"Neural Net1\": MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(800, 48), learning_rate='adaptive'),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Adaboost\": AdaBoostClassifier(n_estimators= 200),\n",
    "    \"ExtraTree\": ExtraTreesClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classifiers_count = len(classifiers_list.keys())\n",
    " \n",
    "def classify_fn(X_train, Y_train, X_test, Y_test, verbose = True):\n",
    "    df_results = pd.DataFrame(data=np.zeros(shape=(classifiers_count,5)), columns = ['classifier', 'Recall', 'F1', 'Precision', 'Accuracy'])\n",
    "    count = 0\n",
    "    for c_name, classifier in classifiers_list.items():\n",
    "        \n",
    "        classifier.fit(X_train, Y_train)\n",
    "        pred = []\n",
    "        pred = classifier.predict(X_test)\n",
    "        \n",
    "        \n",
    "        cv1 = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "        scores = cross_val_score(classifier, final_tr_set, final_tr_pred, cv=cv1)\n",
    "        print ('Classifier', c_name)\n",
    "        print ('Cross validation', scores)\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "        recall = recall_score(Y_test, pred, average='weighted')\n",
    "        f1 = f1_score(Y_test, pred, average='weighted')\n",
    "        p = precision_score(Y_test, pred, average='weighted')\n",
    "        acc =  accuracy_score(Y_test, pred)\n",
    "        \n",
    "        \n",
    "        df_results.loc[count,'classifier'] = c_name\n",
    "        df_results.loc[count,'Recall'] = recall\n",
    "        df_results.loc[count,'F1'] = f1\n",
    "        df_results.loc[count,'Precision'] = p\n",
    "        df_results.loc[count,'Accuracy'] = acc\n",
    "        \n",
    "        count+=1\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Classifier', 'Gradient Boosting Classifier')\n",
      "('Cross validation', array([ 0.89349112,  0.87573964,  0.93491124,  0.92307692,  0.91715976]))\n",
      "Accuracy: 0.91 (+/- 0.04)\n",
      "('Classifier', 'Adaboost')\n",
      "('Cross validation', array([ 0.8816568 ,  0.88757396,  0.94674556,  0.92307692,  0.92307692]))\n",
      "Accuracy: 0.91 (+/- 0.05)\n",
      "('Classifier', 'Neural Net1')\n",
      "('Cross validation', array([ 0.87573964,  0.8816568 ,  0.92307692,  0.88757396,  0.92899408]))\n",
      "Accuracy: 0.90 (+/- 0.04)\n",
      "('Classifier', 'Logistic Regression')\n",
      "('Cross validation', array([ 0.87573964,  0.8816568 ,  0.92307692,  0.88757396,  0.92307692]))\n",
      "Accuracy: 0.90 (+/- 0.04)\n",
      "('Classifier', 'Decision Tree')\n",
      "('Cross validation', array([ 0.89940828,  0.82840237,  0.9112426 ,  0.90532544,  0.90532544]))\n",
      "Accuracy: 0.89 (+/- 0.06)\n",
      "('Classifier', 'ExtraTree')\n",
      "('Cross validation', array([ 0.90532544,  0.89349112,  0.9408284 ,  0.90532544,  0.91715976]))\n",
      "Accuracy: 0.91 (+/- 0.03)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\saish\\anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\saish\\anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Classifier', 'Naive Bayes')\n",
      "('Cross validation', array([ 0.87573964,  0.8816568 ,  0.91715976,  0.88757396,  0.91715976]))\n",
      "Accuracy: 0.90 (+/- 0.04)\n",
      "('Classifier', 'Linear SVM')\n",
      "('Cross validation', array([ 0.87573964,  0.8816568 ,  0.91715976,  0.88757396,  0.91715976]))\n",
      "Accuracy: 0.90 (+/- 0.04)\n",
      "('Classifier', 'Nearest Neighbors')\n",
      "('Cross validation', array([ 0.87573964,  0.8816568 ,  0.91715976,  0.88757396,  0.91715976]))\n",
      "Accuracy: 0.90 (+/- 0.04)\n",
      "('Classifier', 'Random Forest')\n",
      "('Cross validation', array([ 0.8816568 ,  0.86982249,  0.92899408,  0.89349112,  0.92307692]))\n",
      "Accuracy: 0.90 (+/- 0.05)\n",
      "                     classifier    Recall        F1  Precision  Accuracy\n",
      "0  Gradient Boosting Classifier  0.953975  0.951432   0.951245  0.953975\n",
      "2                   Neural Net1  0.937238  0.935266   0.933989  0.937238\n",
      "1                      Adaboost  0.941423  0.931877   0.939721  0.941423\n",
      "4                 Decision Tree  0.895397  0.901444   0.909757  0.895397\n",
      "3           Logistic Regression  0.916318  0.885984   0.923410  0.916318\n",
      "9                 Random Forest  0.907950  0.874582   0.887502  0.907950\n",
      "5                     ExtraTree  0.903766  0.858081   0.816792  0.903766\n",
      "7                    Linear SVM  0.903766  0.858081   0.816792  0.903766\n",
      "8             Nearest Neighbors  0.903766  0.858081   0.816792  0.903766\n",
      "6                   Naive Bayes  0.820084  0.832890   0.847587  0.820084\n"
     ]
    }
   ],
   "source": [
    "df_results = classify_fn(final_tr_set_svd, final_tr_pred, final_vl_set_svd, final_vl_pred)\n",
    "print(df_results.sort_values(by='F1', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFIERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb = gb.fit(final_tr_set_svd, final_tr_pred)\n",
    "\n",
    "\n",
    "pred = []\n",
    "pred = gb.predict(ts_svd)\n",
    "\n",
    "fo=open('C:/Users/saish/Desktop/A_PR2/SVD/format_gb.txt','a+')\n",
    "for i in range (len(pred)):\n",
    "    #print ('i',pred[i])\n",
    "    fo.write(pred[i]+'\\n')\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ab = AdaBoostClassifier(n_estimators= 100)\n",
    "ab = ab.fit(final_tr_set_svd, final_tr_pred)\n",
    "\n",
    "pred = []\n",
    "pred = ab.predict(ts_svd)\n",
    "#print pred\n",
    "\n",
    "fo=open('C:/Users/saish/Desktop/A_PR2/SVD/format_AB.txt','a+')\n",
    "for i in range (len(pred)):\n",
    "    #print ('i',pred[i])\n",
    "    fo.write(pred[i]+'\\n')\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "et = ExtraTreesClassifier()\n",
    "et = et.fit(final_tr_set_svd, final_tr_pred)\n",
    "\n",
    "\n",
    "pred = []\n",
    "pred = et.predict(ts_svd)\n",
    "#print pred\n",
    "\n",
    "fo=open('C:/Users/saish/Desktop/A_PR2/SVD/format_et.txt','a+')\n",
    "for i in range (len(pred)):\n",
    "    #print ('i',pred[i])\n",
    "    fo.write(pred[i]+'\\n')\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "sv = SVC()\n",
    "sv = sv.fit(final_tr_set_svd, final_tr_pred)\n",
    "\n",
    "\n",
    "pred = []\n",
    "pred = sv.predict(ts_svd)\n",
    "#print pred\n",
    "\n",
    "fo=open('C:/Users/saish/Desktop/A_PR2/SVD/format_sv.txt','a+')\n",
    "for i in range (len(pred)):\n",
    "    #print ('i',pred[i])\n",
    "    fo.write(pred[i]+'\\n')\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb = BernoulliNB()\n",
    "nb = nb.fit(final_tr_set_svd, final_tr_pred)\n",
    "\n",
    "\n",
    "pred = []\n",
    "pred = nb.predict(ts_svd)\n",
    "#print pred\n",
    "\n",
    "fo=open('C:/Users/saish/Desktop/A_PR2/SVD/format_nb.txt','a+')\n",
    "for i in range (len(pred)):\n",
    "    #print ('i',pred[i])\n",
    "    fo.write(pred[i]+'\\n')\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf = rf.fit(final_tr_set_svd, final_tr_pred)\n",
    "\n",
    "\n",
    "pred = []\n",
    "pred = rf.predict(ts_svd)\n",
    "#print pred\n",
    "\n",
    "fo=open('C:/Users/saish/Desktop/A_PR2/SVD/format_rf.txt','a+')\n",
    "for i in range (len(pred)):\n",
    "    #print ('i',pred[i])\n",
    "    fo.write(pred[i]+'\\n')\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "nn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100,50), random_state=1)\n",
    "nn = nn.fit(final_tr_set_svd, final_tr_pred)\n",
    "\n",
    "\n",
    "pred = []\n",
    "pred = nn.predict(ts_svd)\n",
    "#print pred\n",
    "\n",
    "fo=open('C:/Users/saish/Desktop/A_PR2/SVD/format_nn.txt','a+')\n",
    "for i in range (len(pred)):\n",
    "    #print ('i',pred[i])\n",
    "    fo.write(pred[i]+'\\n')\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "nn = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(400,2), learning_rate='adaptive')\n",
    "nn = nn.fit(final_tr_set_svd, final_tr_pred)\n",
    "\n",
    "\n",
    "pred = []\n",
    "pred = nn.predict(ts_svd)\n",
    "#print pred\n",
    "\n",
    "fo=open('C:/Users/saish/Desktop/A_PR2/SVD/format_nn_1.txt','a+')\n",
    "for i in range (len(pred)):\n",
    "    #print ('i',pred[i])\n",
    "    fo.write(pred[i]+'\\n')\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "lr = LogisticRegression()\n",
    "lr = lr.fit(final_tr_set_svd, final_tr_pred)\n",
    "\n",
    "\n",
    "pred = []\n",
    "pred = lr.predict(ts_svd)\n",
    "#print pred\n",
    "\n",
    "fo=open('C:/Users/saish/Desktop/A_PR2/SVD/format_lr.txt','a+')\n",
    "for i in range (len(pred)):\n",
    "    #print ('i',pred[i])\n",
    "    fo.write(pred[i]+'\\n')\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(final_tr_set_svd, final_tr_pred)\n",
    "\n",
    "\n",
    "pred = []\n",
    "pred = dt.predict(ts_svd)\n",
    "#print pred\n",
    "\n",
    "fo=open('C:/Users/saish/Desktop/A_PR2/SVD/format_dt.txt','a+')\n",
    "for i in range (len(pred)):\n",
    "    #print ('i',pred[i])\n",
    "    fo.write(pred[i]+'\\n')\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
